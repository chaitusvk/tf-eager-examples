{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.datasets import boston_housing\n",
    "from tensorflow.contrib.eager.python import tfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Eager exeution Mode\n",
    "tf.enable_eager_execution()\n",
    "tf.set_random_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "batch_size = 128\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train (404, 13) 2.6029783389231392e-15 0.9999999879626582\n",
      "y train (404,) 22.395049504950492 9.199035423364862\n",
      "x test (102, 13) 0.020826991529340172 0.9836083314719052\n",
      "y test (102,) 23.07843137254902 9.123806690181466\n"
     ]
    }
   ],
   "source": [
    "# dataset loading\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# normalization of dataset\n",
    "mean = x_train.mean(axis=0)\n",
    "std = x_train.std(axis=0)\n",
    "\n",
    "x_train = (x_train - mean) / (std + 1e-8)\n",
    "x_test = (x_test - mean) / (std + 1e-8)\n",
    "\n",
    "print('x train', x_train.shape, x_train.mean(), x_train.std())\n",
    "print('y train', y_train.shape, y_train.mean(), y_train.std())\n",
    "print('x test', x_test.shape, x_test.mean(), x_test.std())\n",
    "print('y test', y_test.shape, y_test.mean(), y_test.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Keras Model\n",
    "\n",
    "The canonical way to define our models in Eager mode is to extend tf.keras.Model, which will manage all of the Keras layers or other Keras Models that are added to this class.\n",
    "\n",
    "An idiosyncrasy of how this model's layers is managed is that when you build the model and call Model.summary(), **the layer names will be in the order of how they were assigned inside `__init__`, NOT the way they are called inside `call()`**. \n",
    "\n",
    "Another issue is that it assumes you know how many layers you will need before `call`. This may not be the case in certain instances, like ResNet or Inception, where you can have more layers to increase depth. This can be managed, by using a `setattr(self, 'some_unique_key_name', layer)` dynamically. This technique will be shown later in `05_inception.py` and `05_resnet.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition (canonical way)\n",
    "class Regressor(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        output = self.dense(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The benefit of extending a tf.keras Model, is that you can use **all of the utility functions provided by Keras** just as you would use them normally.\n",
    "\n",
    "However, there is currently a minor bug in TF <1.8 where if you call Model.fit() right after building it, it will **try to pass the entire dataset (X and Y which is passed to `.fit()` as arguments) to determine the shapes of the model's layers**. \n",
    "\n",
    "While lazy layer building is generally great, and it bypasses PyTorch's requirement to know the input dimentions for every layer, it causes a severe problem if you try to pass a dataset such as MNIST (60000, 784) as a single \"batch\" to determine the shape. Almost all small GPUs will choke and raise an OOM error at that point. For larger models with hundreds of layers, even a 1080Ti will take a long time to handle that.\n",
    "\n",
    "Fortunately, there are several easy possible fixes : \n",
    "\n",
    "- Use `Model.fit_generator()` instead of `Model.fit()`. Since the generator will only pass the first batch to determine the shape, it wont cause an issue.\n",
    "- Call the model explictly using `Model._set_inputs()` with a dummy tensorflow batch containing a single sample of the shape of the dataset (for MNIST, that is (1, 784)) to force build the model. I'll be using this throughout, since it makes more sence than writing generators for `fit_generator` for small datasets like MNIST, Fasion MNIST and Boston Housing.\n",
    "- Write your own training loop. But we are using a Keras Model, why bother with that unless we absolutely have to?\n",
    "\n",
    "# Note on building models\n",
    "It is best to build the model once after creating using an explicit `Model._set_inputs()` and passing it a tensorflow batch prior to performing any task - `Model.fit()/evaluate()/predict()` and prior to loading a trained model checkpoint. \n",
    "\n",
    "Generally, always build your model once before doing **anything.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/25\n",
      "404/404 [==============================] - 0s 175us/step - loss: 390.5196 - val_loss: 165.9927\n",
      "Epoch 2/25\n",
      "404/404 [==============================] - 0s 76us/step - loss: 92.1832 - val_loss: 35.1868\n",
      "Epoch 3/25\n",
      "404/404 [==============================] - 0s 94us/step - loss: 33.6750 - val_loss: 24.9811\n",
      "Epoch 4/25\n",
      "404/404 [==============================] - 0s 93us/step - loss: 27.8796 - val_loss: 24.6056\n",
      "Epoch 5/25\n",
      "404/404 [==============================] - 0s 104us/step - loss: 28.7049 - val_loss: 19.6881\n",
      "Epoch 6/25\n",
      "404/404 [==============================] - 0s 77us/step - loss: 24.2545 - val_loss: 21.2796\n",
      "Epoch 7/25\n",
      "404/404 [==============================] - 0s 88us/step - loss: 23.1641 - val_loss: 33.9938\n",
      "Epoch 8/25\n",
      "404/404 [==============================] - 0s 79us/step - loss: 26.8610 - val_loss: 22.0381\n",
      "Epoch 9/25\n",
      "404/404 [==============================] - 0s 94us/step - loss: 23.2845 - val_loss: 50.6019\n",
      "Epoch 10/25\n",
      "404/404 [==============================] - 0s 90us/step - loss: 31.1411 - val_loss: 25.8182\n",
      "Epoch 11/25\n",
      "404/404 [==============================] - 0s 92us/step - loss: 24.0944 - val_loss: 22.9388\n",
      "Epoch 12/25\n",
      "404/404 [==============================] - 0s 82us/step - loss: 23.8981 - val_loss: 23.7770\n",
      "Epoch 13/25\n",
      "404/404 [==============================] - 0s 98us/step - loss: 23.0437 - val_loss: 25.8289\n",
      "Epoch 14/25\n",
      "404/404 [==============================] - 0s 87us/step - loss: 23.1463 - val_loss: 23.8966\n",
      "Epoch 15/25\n",
      "404/404 [==============================] - 0s 84us/step - loss: 23.0283 - val_loss: 32.2666\n",
      "Epoch 16/25\n",
      "404/404 [==============================] - 0s 88us/step - loss: 23.5559 - val_loss: 30.5591\n",
      "Epoch 17/25\n",
      "404/404 [==============================] - 0s 87us/step - loss: 23.2350 - val_loss: 22.8398\n",
      "Epoch 18/25\n",
      "404/404 [==============================] - 0s 97us/step - loss: 23.0330 - val_loss: 22.1668\n",
      "Epoch 19/25\n",
      "404/404 [==============================] - 0s 97us/step - loss: 24.0458 - val_loss: 24.4576\n",
      "Epoch 20/25\n",
      "404/404 [==============================] - 0s 93us/step - loss: 22.8083 - val_loss: 20.3023\n",
      "Epoch 21/25\n",
      "404/404 [==============================] - 0s 82us/step - loss: 22.9089 - val_loss: 20.6257\n",
      "Epoch 22/25\n",
      "404/404 [==============================] - 0s 80us/step - loss: 23.9981 - val_loss: 21.5275\n",
      "Epoch 23/25\n",
      "404/404 [==============================] - 0s 93us/step - loss: 22.7487 - val_loss: 22.6786\n",
      "Epoch 24/25\n",
      "404/404 [==============================] - 0s 89us/step - loss: 22.9143 - val_loss: 20.3094\n",
      "Epoch 25/25\n",
      "404/404 [==============================] - 0s 95us/step - loss: 23.8303 - val_loss: 22.4886\n",
      "Test MSE : 22.48859977722168\n"
     ]
    }
   ],
   "source": [
    "device = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\n",
    "\n",
    "with tf.device(device):\n",
    "    # build model and optimizer\n",
    "    model = Regressor()\n",
    "    model.compile(optimizer=tf.train.GradientDescentOptimizer(0.1), loss='mse')\n",
    "\n",
    "    # suggested fix for TF <= 2.0; can be incorporated inside `_eager_set_inputs` or `_set_input`\n",
    "    # Fix = Use exactly one sample from the provided input dataset to determine input/output shape/s for the model\n",
    "    dummy_x = tf.zeros((1, 13))\n",
    "    model._set_inputs(dummy_x)\n",
    "\n",
    "    # train\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=(x_test, y_test))\n",
    "\n",
    "    # evaluate on test set\n",
    "    scores = model.evaluate(x_test, y_test, batch_size, verbose=2)\n",
    "    print(\"Test MSE :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
